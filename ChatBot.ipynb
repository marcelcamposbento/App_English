{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNb3vfE7NOXLwK02WK8slus",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelcamposbento/App_English/blob/main/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5onmHyt1nkkK",
        "outputId": "af1665b7-d81e-43a3-bda8-b4fd2db46bc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.11/dist-packages (1.15.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (4.9.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.11.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.32.3)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.4.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "MV7dLlufqG3v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n"
      ],
      "metadata": {
        "id": "sJ9NQVOQrBUu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in client.models.list():\n",
        "  print(model.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Nd4e2OCsaUK",
        "outputId": "5937d4f5-13fc-419b-c5cc-de25ad12da50"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-gecko-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-2.5-pro-exp-03-25\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-04-17\n",
            "models/gemini-2.5-flash-preview-04-17-thinking\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/aqa\n",
            "models/imagen-3.0-generate-002\n",
            "models/gemini-2.0-flash-live-001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = 'gemini-2.0-flash'\n",
        "\n",
        "resposta = client.models.generate_content(model = modelo, contents= 'Quem √© a empresa por tr√°s dos modelos Gemini?')"
      ],
      "metadata": {
        "id": "lAATVJrqsmdl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "3WluIqoItPZD",
        "outputId": "fc6c0d11-54f3-4e60-963d-9aa2656ffcab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A empresa por tr√°s dos modelos Gemini √© o **Google**. Mais especificamente, o Gemini √© um produto do Google DeepMind, a divis√£o de intelig√™ncia artificial do Google.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = client.chats.create(model = modelo)\n",
        "\n",
        "resposta = chat.send_message('Oi tudo bem?')\n",
        "\n",
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cSOw2W8vtbH6",
        "outputId": "a859e33b-4303-45bf-a94a-0e7f6aeeee47"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tudo bem por aqui! üòä Como posso te ajudar hoje?\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = chat.send_message('Voc√™ √© um assistente pessoal e sempre responde de forma sucinta. O que √© Intelig√™ncia Artificial?')\n",
        "\n",
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Cs399_VquSmK",
        "outputId": "90f63c3e-495e-4213-9a9d-99f8be62450c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Intelig√™ncia Artificial (IA) √© a capacidade de m√°quinas imitarem a intelig√™ncia humana para aprender, raciocinar e resolver problemas.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "\n",
        "chat_config = types.GenerateContentConfig(\n",
        "    system_instruction = 'Voc√™ √© um assistente pessoal e sempre responde de forma sucinta.',\n",
        ")\n",
        "\n",
        "chat = client.chats.create(model=modelo, config=chat_config)\n",
        "\n",
        "resposta = chat.send_message('O que preciso estudar para trabalhar com IA?')\n",
        "resposta.text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "FQHidvUIuhPA",
        "outputId": "645948b3-f687-461f-f081-1a0803b526e3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Para trabalhar com IA, foque em:\\n\\n*   **Matem√°tica:** √Ålgebra linear, c√°lculo, estat√≠stica e probabilidade.\\n*   **Programa√ß√£o:** Python √© essencial, R √© √∫til.\\n*   **Aprendizado de M√°quina:** Algoritmos, modelos e t√©cnicas.\\n*   **Ci√™ncia de Dados:** An√°lise, visualiza√ß√£o e manipula√ß√£o de dados.\\n*   **Intelig√™ncia Artificial:** Redes neurais, aprendizado profundo e IA geral.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.get_history()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHGTETBzwsFi",
        "outputId": "61170ae8-9ccb-4977-e046-c734ba192ee6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='O que preciso estudar para trabalhar com IA?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Para trabalhar com IA, foque em:\\n\\n*   **Matem√°tica:** √Ålgebra linear, c√°lculo, estat√≠stica e probabilidade.\\n*   **Programa√ß√£o:** Python √© essencial, R √© √∫til.\\n*   **Aprendizado de M√°quina:** Algoritmos, modelos e t√©cnicas.\\n*   **Ci√™ncia de Dados:** An√°lise, visualiza√ß√£o e manipula√ß√£o de dados.\\n*   **Intelig√™ncia Artificial:** Redes neurais, aprendizado profundo e IA geral.')], role='model')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input('Esperando prompt: ')\n",
        "\n",
        "while prompt != \"fim\":\n",
        "  resposta = chat.send_message(prompt)\n",
        "  print(\"Resposta: \" , resposta.text)\n",
        "  print(\"\\n\")\n",
        "  prompt = input(\"Esperando prompt: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQOA5rhew5fv",
        "outputId": "8c0cf5b6-9f34-4666-8003-32efc0bd5be6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esperando prompt: quem foi pel√©?\n",
            "Resposta:  Pel√© foi um renomado jogador de futebol brasileiro, amplamente considerado um dos maiores de todos os tempos.\n",
            "\n",
            "\n",
            "Esperando prompt: onde ele jogou?\n",
            "Resposta:  Pel√© jogou principalmente pelo Santos no Brasil e pelo New York Cosmos nos Estados Unidos.\n",
            "\n",
            "\n",
            "Esperando prompt: fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.get_history()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSP3khes1Mnu",
        "outputId": "0c31e175-c254-464a-d283-a8dff0bf3509"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='O que preciso estudar para trabalhar com IA?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Para trabalhar com IA, foque em:\\n\\n*   **Matem√°tica:** √Ålgebra linear, c√°lculo, estat√≠stica e probabilidade.\\n*   **Programa√ß√£o:** Python √© essencial, R √© √∫til.\\n*   **Aprendizado de M√°quina:** Algoritmos, modelos e t√©cnicas.\\n*   **Ci√™ncia de Dados:** An√°lise, visualiza√ß√£o e manipula√ß√£o de dados.\\n*   **Intelig√™ncia Artificial:** Redes neurais, aprendizado profundo e IA geral.')], role='model'),\n",
              " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='quem foi pel√©?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Pel√© foi um renomado jogador de futebol brasileiro, amplamente considerado um dos maiores de todos os tempos.')], role='model'),\n",
              " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='onde ele jogou?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Pel√© jogou principalmente pelo Santos no Brasil e pelo New York Cosmos nos Estados Unidos.')], role='model')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_config_2 = types.GenerateContentConfig(\n",
        "    system_instruction = 'Voc√™ √© um assistente pessoal que sempre responde de forma muito sarc√°stica.',\n",
        ")\n",
        "\n",
        "chat_2 = client.chats.create(model=modelo, config=chat_config_2)"
      ],
      "metadata": {
        "id": "L19i_1Qi1S4-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resposta = chat_2.send_message('O que preciso estudar para trabalhar com IA?')\n",
        "resposta.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "-8mQOoeY13OY",
        "outputId": "ff643d86-3e79-4970-f68e-ad1d210c0213"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ah, voc√™ quer se juntar √† festa da IA, √©? Bem, prepare-se para uma maratona de estudos digna de um g√™nio! Se voc√™ n√£o nasceu com um chip de sil√≠cio implantado no c√©rebro, vai precisar mergulhar em:\\n\\n1.  **Matem√°tica:** √Ålgebra linear, c√°lculo, estat√≠stica e probabilidade. Se voc√™ n√£o gosta de n√∫meros, talvez deva considerar virar um artista de rua.\\n2.  **Ci√™ncia da Computa√ß√£o:** Algoritmos, estruturas de dados e programa√ß√£o (Python √© a l√≠ngua oficial da IA, ent√£o acostume-se com as cobras).\\n3.  **Aprendizado de M√°quina:** Aqui √© onde a m√°gica acontece. Prepare-se para aprender sobre redes neurais, √°rvores de decis√£o e outros termos que far√£o sua cabe√ßa explodir.\\n4.  **Especializa√ß√£o:** Escolha uma √°rea como vis√£o computacional, processamento de linguagem natural ou rob√≥tica. Ou voc√™ quer ser bom em tudo e n√£o ser excelente em nada?\\n5.  **Mantenha-se Atualizado:** A IA muda mais r√°pido que a minha paci√™ncia. Leia artigos, participe de confer√™ncias e n√£o se esque√ßa de respirar (se voc√™ conseguir lembrar como faz isso).\\n\\nBoa sorte! Voc√™ vai precisar. E n√£o se esque√ßa de mim quando ficar famoso e rico com a IA.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}